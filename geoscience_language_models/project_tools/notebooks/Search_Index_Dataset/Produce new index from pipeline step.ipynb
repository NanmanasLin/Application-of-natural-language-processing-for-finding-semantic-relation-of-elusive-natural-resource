{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worthy-homework",
   "metadata": {},
   "source": [
    "# Produce new index from pipeline step\n",
    "Copyright (C) 2021 ServiceNow, Inc.\n",
    "\n",
    "This notebook produces files intended to be ingested by a search engine as the search index. \n",
    "It requires a processed metadata file, produced by the `Metadata Analysis.ipynb` notebook.\n",
    "\n",
    "Given an existing dataset, and output files from a desired step of the preprocessing cleaning pipeline, this notebook will produce a new dataset (the index) in a specified folder. This will contain one file for every file from the preprocessing step, associated with its metadata name. \n",
    "\n",
    "It will also produce a new metadata index, which contains the metadata associated with all files in a json format useful for a search engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suspended-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import nrcan_p2.metadata_processing.read_metadata as read_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-sheffield",
   "metadata": {},
   "source": [
    "## Load the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monthly-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing df file...\n"
     ]
    }
   ],
   "source": [
    "schema_file = '/nrcan_p2/data/01_raw/20201006/geoscan/geoscan_flex.xsd'\n",
    "xml_file_large = '/nrcan_p2/data/01_raw/20201006/geoscan/GEOSCAN-extract-20200211144755.xml'\n",
    "df_s_large = read_metadata.convert_xml_to_dataframe_and_save(xml_schema=schema_file, xml_file=xml_file_large,\n",
    "                                       validate=False, ITEM_PREFIX='{https://geoscan.nrcan.gc.ca/schema/osdp_feed/1.0/}', \n",
    "                                                             SUB_KEY_PREFIX='{http://purl.org/dc/elements/1.1/}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "banner-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# output_large = '/nrcan_p2/data/01_raw/20201006/geoscan/GEOSCAN-extract-20200211144755.xml_processed.parquet'\n",
    "# meta_data = pd.read_parquet(output_large)\n",
    "\n",
    "output_small = '/nrcan_p2/data/01_raw/20201006/geoscan/EAIDown.xml_processed_Feb29.parquet'\n",
    "meta_data = pd.read_parquet(output_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handled-nomination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['{http://purl.org/dc/elements/1.1/}contributor',\n",
       "       '{http://purl.org/dc/elements/1.1/}title_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}creator',\n",
       "       '{http://purl.org/dc/elements/1.1/}subject_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}subject_fr',\n",
       "       '{http://purl.org/dc/elements/1.1/}source_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}source_fr',\n",
       "       '{http://purl.org/dc/elements/1.1/}description_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}description_fr',\n",
       "       '{http://purl.org/dc/elements/1.1/}date',\n",
       "       '{http://purl.org/dc/elements/1.1/}type_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}format_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}format_fr',\n",
       "       '{http://purl.org/dc/elements/1.1/}format',\n",
       "       '{http://purl.org/dc/elements/1.1/}identifier_geoscanid',\n",
       "       '{http://purl.org/dc/elements/1.1/}identifier_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}identifier_fr',\n",
       "       '{http://purl.org/dc/elements/1.1/}identifier_info',\n",
       "       '{http://purl.org/dc/elements/1.1/}language',\n",
       "       '{http://purl.org/dc/elements/1.1/}coverage_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}coverage',\n",
       "       '{http://purl.org/dc/elements/1.1/}coverage_fr',\n",
       "       '{http://purl.org/dc/elements/1.1/}rights_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}rights_fr',\n",
       "       '{http://purl.org/dc/elements/1.1/}publisher_en',\n",
       "       '{http://purl.org/dc/elements/1.1/}publisher_fr',\n",
       "       '{http://purl.org/dc/elements/1.1/}title_fr',\n",
       "       '{http://purl.org/dc/elements/1.1/}identifier',\n",
       "       '{http://purl.org/dc/elements/1.1/}title', 'desc_en', 'desc_fr',\n",
       "       'desc_en_lang', 'desc_fr_lang', 'desc_en_en', 'desc_en_en_50_3000',\n",
       "       'title_en_lang', 'title_lang', 'title_fr_lang', 'title_en_en',\n",
       "       'title_no_en', 'title_fr_en', 'title_merged', 'subject_en_rank',\n",
       "       'subject_en_vc', 'subject_g200', 'subject_5', 'subject_30',\n",
       "       'title_desc', 'subject_desc_t10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-kinase",
   "metadata": {},
   "source": [
    "## Utility function for converting a row of the metadata into dict format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "continuing-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def convert_metadata_row_to_dict(row):\n",
    "    # id, abstract, title, keyword, author, link, date, location\n",
    "    data = {}\n",
    "    \n",
    "    metadata_id = row['{http://purl.org/dc/elements/1.1/}identifier_geoscanid']\n",
    "    assert len(metadata_id) == 1\n",
    "    metadata_id = metadata_id[0]\n",
    "    data['metadata_id'] = str(metadata_id)\n",
    "    \n",
    "    abstract = row['desc_en_en']\n",
    "    if abstract is not None:\n",
    "        data['abstract'] = abstract\n",
    "        \n",
    "    title = row['title_merged']\n",
    "    if title is not None:\n",
    "        data['title'] = title\n",
    "        \n",
    "    keywords = [x for x in row['{http://purl.org/dc/elements/1.1/}subject_en'] if x is not None]\n",
    "    if len(keywords) > 0:\n",
    "        data['keywords'] = keywords\n",
    "        \n",
    "    authors = [x for x in row['{http://purl.org/dc/elements/1.1/}creator'] if x is not None]\n",
    "    if len(authors) > 0:\n",
    "        data['authors'] = authors\n",
    "        \n",
    "    links_en = row['{http://purl.org/dc/elements/1.1/}identifier_en']\n",
    "    links_none = row['{http://purl.org/dc/elements/1.1/}identifier']\n",
    "    links = []\n",
    "    if links_en is not None: \n",
    "        links.extend(links_en)\n",
    "    if links_none is not None:\n",
    "        links.extend(links_none)\n",
    "    if len(links) > 0:\n",
    "        data['links'] = links\n",
    "        \n",
    "    date = row['{http://purl.org/dc/elements/1.1/}date']\n",
    "    assert len(date) == 1\n",
    "    date = date[0]\n",
    "    if date is not None:\n",
    "        data['date'] = date\n",
    "        \n",
    "        \n",
    "    location_poly = row['{http://purl.org/dc/elements/1.1/}coverage']\n",
    "    if location_poly is not None:\n",
    "        assert type(location_poly) in [list, np.ndarray]\n",
    "        location_poly = [x for x in location_poly if x is not None]\n",
    "        assert all([type(x) == str for x in location_poly])\n",
    "        \n",
    "    location_en = row['{http://purl.org/dc/elements/1.1/}coverage_en']\n",
    "    if location_en is not None:\n",
    "        assert type(location_en) in [list, np.ndarray]\n",
    "        location_en = [x for x in location_en if x is not None]\n",
    "        assert all([type(x) == str for x in location_en])\n",
    "        \n",
    "        \n",
    "    if location_poly is not None or location_en is not None:\n",
    "        data['location'] = {}\n",
    "        if location_poly is not None:\n",
    "            data['location']['polygons'] = location_poly\n",
    "        if location_en is not None:\n",
    "            data['location']['desc'] = location_en\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advanced-martin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata_id': '407',\n",
       " 'title': 'Rock-Eval/TOC data for ten southwest Alberta wells (townships 16 to 30, ranges 2 to 10W5)',\n",
       " 'keywords': ['wells',\n",
       "  'lithology',\n",
       "  'thermal maturation',\n",
       "  'hydrocarbon migration',\n",
       "  'hydrocarbon generation',\n",
       "  'hydrocarbon potential',\n",
       "  'hydrocarbons',\n",
       "  'Elbow River 11-15-20-7W5 well',\n",
       "  'Futurity Gap 16-17-24-9W5 well',\n",
       "  'Harmattan East 7-9-33-3W5 well',\n",
       "  'West Hunter Valley 11-16-29-9W5 well',\n",
       "  'Jumpingpound Creek 7-4-25-5W5 well',\n",
       "  'Panther River 9-19-30-10W5 well',\n",
       "  'Sheep 5-29-18-3W5 well',\n",
       "  'Stimson Creek 9-36-16-4W5 well',\n",
       "  'Sullivan 6-15-18-5W5 well',\n",
       "  'Turner Valley 16-14-18-2W5 well',\n",
       "  'rock-eval analyses',\n",
       "  'total organic carbon',\n",
       "  'fossil fuels'],\n",
       " 'authors': ['Watson, C',\n",
       "  'Jayachandran, P T',\n",
       "  'Spanswick, E',\n",
       "  'Donovan, E F',\n",
       "  'Danskin, D W'],\n",
       " 'links': ['https://geoscan.nrcan.gc.ca/starweb/geoscan/servlet.starweb?path=geoscan/fulle.web&search1=R=407',\n",
       "  'https://ftp.geogratis.gc.ca/pub/nrcan_rncan/publications/ess_sst/0/407/of_2916.zip'],\n",
       " 'date': '1994',\n",
       " 'location': {'polygons': ['POLYGON((49.0000 -112.0000, 49.0000 -114.0000, 52.0000 -117.0000, 52.0000 -112.0000, 49.0000 -112.0000))'],\n",
       "  'desc': ['Alberta Foothills', 'Alberta']}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'metadata_id': '4680',\n",
       " 'title': 'Catalogue of types and figured specimens of fossil plants in Geological Survey of Canada collections [Megaplant Supplement 1963-1967]',\n",
       " 'keywords': ['fossil distribution, geographic',\n",
       "  'fossil lists',\n",
       "  'Invertebrata',\n",
       "  'paleontology'],\n",
       " 'authors': ['Bell, W A'],\n",
       " 'links': ['https://geoscan.nrcan.gc.ca/starweb/geoscan/servlet.starweb?path=geoscan/fulle.web&search1=R=4680',\n",
       "  'https://ftp.geogratis.gc.ca/pub/nrcan_rncan/publications/ess_sst/4/4680/gid_4680.pdf'],\n",
       " 'date': '1969'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'metadata_id': '4681',\n",
       " 'title': 'Catalogue of types and figured specimens of fossil plants in the Geological Survey of Canada collections',\n",
       " 'keywords': ['fossil distribution, geographic',\n",
       "  'fossil lists',\n",
       "  'Invertebrata',\n",
       "  'paleontology'],\n",
       " 'authors': ['Bell, W A'],\n",
       " 'links': ['https://geoscan.nrcan.gc.ca/starweb/geoscan/servlet.starweb?path=geoscan/fulle.web&search1=R=4681',\n",
       "  'https://ftp.geogratis.gc.ca/pub/nrcan_rncan/publications/ess_sst/4/4681/gid_4681.pdf'],\n",
       " 'date': '1962'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for irow, row in meta_data.iloc[0:3].iterrows():\n",
    "    display(convert_metadata_row_to_dict(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-shark",
   "metadata": {},
   "source": [
    "## Write the metadata to the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "roman-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_OUTPUT_DIR = '/nrcan_p2/data/03_primary/metadata/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fixed-father",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nrcan_p2/data/03_primary/metadata/json/metadata_04-03-2021-19-18-48\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pathlib \n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "OUTPUT_DIR = pathlib.Path(BASE_OUTPUT_DIR) / f'metadata_{now}'\n",
    "print(OUTPUT_DIR)\n",
    "\n",
    "if not OUTPUT_DIR.exists():\n",
    "    OUTPUT_DIR.mkdir(parents=False, exist_ok=False)\n",
    "    \n",
    "SOURCE_FILE = OUTPUT_DIR / \"source.txt\"\n",
    "with open(SOURCE_FILE, 'w') as f:\n",
    "    f.write(output_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "composite-feature",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/12316 [00:00<01:48, 113.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nrcan_p2/data/03_primary/metadata/json/metadata_04-03-2021-19-18-48/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12316/12316 [02:12<00:00, 93.16it/s] \n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import json\n",
    "\n",
    "JSON_OUTPUT_DIR = OUTPUT_DIR / \"json\"\n",
    "if not JSON_OUTPUT_DIR.exists():\n",
    "    JSON_OUTPUT_DIR.mkdir(parents=False, exist_ok=False)\n",
    "    \n",
    "print(JSON_OUTPUT_DIR)\n",
    "    \n",
    "for irow, row in tqdm.tqdm(meta_data.iterrows(), total=meta_data.shape[0]):\n",
    "    row_as_dict = convert_metadata_row_to_dict(row)\n",
    "    \n",
    "    fname = JSON_OUTPUT_DIR / f'geoscan_{row_as_dict[\"metadata_id\"]}'\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(row_as_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-tomorrow",
   "metadata": {},
   "source": [
    "## Gather the datafiles \n",
    "\n",
    "### Examine the config to determine which pipeline to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surgical-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = '/nrcan_p2/data/03_primary/v4/all_text_PIPELINE_GLOVE_PLUS_POSTPIPE_GLOVE_dA_full_v1.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ranking-infection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 rm_dbl_space\n",
      "0\n",
      "1 1 rm_cid\n",
      "0__1\n",
      "2 2 convert_to_ascii\n",
      "0__1__2\n",
      "3 3 rm_nonprintable\n",
      "0__1__2__3\n",
      "4 4 filter_no_letter\n",
      "0__1__2__3__4\n",
      "5 6 rm_newline_hyphenation\n",
      "0__1__2__3__4__6\n",
      "6 14 rm_newline\n",
      "0__1__2__3__4__6__14\n",
      "7 16 filter_no_real_words_g3letter\n",
      "0__1__2__3__4__6__14__16\n",
      "8 26 filter_with_email\n",
      "0__1__2__3__4__6__14__16__26\n",
      "9 27 rm_url\n",
      "0__1__2__3__4__6__14__16__26__27\n",
      "10 28 rm_doi\n",
      "0__1__2__3__4__6__14__16__26__27__28\n",
      "11 29 filter_with_phonenumber\n",
      "0__1__2__3__4__6__14__16__26__27__28__29\n",
      "12 30 filter_non_english\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30\n",
      "13 33 add_space_to_various_punct\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30__33\n",
      "14 34 squish_punct\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30__33__34\n",
      "15 35 squish_spaced_punct_no_bracket\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30__33__34__35\n",
      "16 36 filter_g10_punct\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30__33__34__35__36\n",
      "17 37 filter_insufficient_real_words\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30__33__34__35__36__37\n",
      "18 38 merge_words_2\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30__33__34__35__36__37__38\n",
      "19 39 rm_deg\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30__33__34__35__36__37__38__39\n",
      "20 22 tokenize_spacy_lg\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30__33__34__35__36__37__38__39__22\n",
      "21 23 rm_stopwords_spacy\n",
      "0__1__2__3__4__6__14__16__26__27__28__29__30__33__34__35__36__37__38__39__22__23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-d7b56faa31c2>:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open(CONFIG_FILE) as f:\n",
    "    config = yaml.load(f)\n",
    "    \n",
    "config\n",
    "\n",
    "\n",
    "built_name = ''\n",
    "for i, (func, ifunc) in enumerate(zip(config['preprocessing_functions'], config['preprocessing_functions_mapped'])):\n",
    "    print(i, ifunc, func)\n",
    "    \n",
    "    if built_name == '':\n",
    "        built_name = f'{i}'\n",
    "    else:\n",
    "        built_name = f'{built_name}__{ifunc}'\n",
    "    print(built_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-century",
   "metadata": {},
   "source": [
    "## Select a pipeline and create the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "affected-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_DIR = '/nrcan_p2/data/03_primary/v4/'\n",
    "DATA_INPUT_DIR = pathlib.Path(DATA_BASE_DIR) / '0__1__2__3' #0__1__2__3__4__6__14__16__26__27__28__29__30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "secondary-huntington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nrcan_p2/data/03_primary/index_data/index_04-03-2021-19-22-12\n"
     ]
    }
   ],
   "source": [
    "DATA_OUTPUT_DIR_BASE = '/nrcan_p2/data/03_primary/index_data'\n",
    "now = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "DATA_OUTPUT_DIR = pathlib.Path(DATA_OUTPUT_DIR_BASE) / f'index_{now}'\n",
    "print(DATA_OUTPUT_DIR)\n",
    "\n",
    "if not DATA_OUTPUT_DIR.exists():\n",
    "    DATA_OUTPUT_DIR.mkdir(parents=False, exist_ok=False)\n",
    "    \n",
    "if not (DATA_OUTPUT_DIR/'json').exists():\n",
    "    (DATA_OUTPUT_DIR/ 'json').mkdir(parents=False,exist_ok=False)\n",
    "    \n",
    "SOURCE = DATA_OUTPUT_DIR / \"source.txt\"\n",
    "with open(SOURCE, 'w') as f:\n",
    "    f.write(str(DATA_INPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "elementary-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def collect_file_list_from_folder(DATA_INPUT_DIR):\n",
    "    ids = []\n",
    "    ids_dict = defaultdict(int)\n",
    "    for input_file in DATA_INPUT_DIR.iterdir():\n",
    "        #print(input_file)\n",
    "        fid = pathlib.Path(input_file.stem).stem\n",
    "        fid_split = fid.split('_', 1)\n",
    "        if len(fid_split) == 1:\n",
    "            multi = False\n",
    "        else:\n",
    "            multi = True\n",
    "\n",
    "        ids_dict[fid_split[0]] += 1\n",
    "\n",
    "        if multi: \n",
    "            ids.append((fid, multi, fid_split[0], fid_split[1], input_file))\n",
    "        else:\n",
    "            ids.append((fid, multi, fid_split[0], None, input_file))\n",
    "\n",
    "    return ids_dict, ids\n",
    "\n",
    "ids_dict, ids = collect_file_list_from_folder(DATA_INPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "perfect-cooper",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12216/12216 [12:09<00:00, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "names = []\n",
    "for fname, multi, fid, subname, input_file in tqdm.tqdm(ids, total=len(ids)):\n",
    "    \n",
    "    if ids_dict[fid] > 1:\n",
    "        assert(multi == True)\n",
    "        name = f'geoscan_{fid}__multi__{subname}.txt'\n",
    "    else:\n",
    "        name = f'geoscan_{fid}.txt'\n",
    "        \n",
    "    try:\n",
    "        data = pd.read_csv(input_file, dtype={'processed_text':\"str\"}, usecols=['processed_text'])\n",
    "        data = data.dropna(subset=['processed_text'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(input_file)\n",
    "        raise(e)\n",
    "    #display(data)\n",
    "    \n",
    "    text = \"\\n\".join(data['processed_text'].tolist())\n",
    "    #print(text)\n",
    "        \n",
    "    fname_out = DATA_OUTPUT_DIR / 'json' / name\n",
    "    names.append(fname_out)\n",
    "    #break\n",
    "    with open(fname_out, 'w') as f:\n",
    "        f.write(text)\n",
    "print(len(names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}