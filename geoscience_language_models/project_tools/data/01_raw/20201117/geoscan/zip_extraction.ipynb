{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir,environ,rename \n",
    "from sys import argv\n",
    "from os.path import isfile,join,basename\n",
    "from shutil import rmtree,move\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/nrcan_p2\"\n",
    "data_dir = join(root_dir,\"data\")\n",
    "geoscan_files_dir=join(data_dir,\"01_raw\",\"20201006\",\"geoscan\")\n",
    "zip_dir=join(geoscan_files_dir,\"raw\",\"zip\")\n",
    "extracted_dir = join(data_dir,\"01_raw\",\"20201117\",\"geoscan\",\"raw\",\"extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## rm -rf /nrcan_p2/data/01_raw/20201117/geoscan/raw/extracted/*\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/extracted/of_pdf\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/extracted/has_pdf_dir\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/extracted/generic_pdfs\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/extracted/txt\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/extracted/wp_rtf\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/extracted/low_text_pdfs\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_zip_files():\n",
    "    return [f for f in listdir(zip_dir) if isfile(join(zip_dir, f))]\n",
    "\n",
    "def get_processed_zips():\n",
    "    extracted_files_paths = glob.glob(extracted_dir+\"/**/processed.txt\")\n",
    "    extracted_files = []\n",
    "    for path in extracted_files_paths:\n",
    "        data = \"\"\n",
    "        with open(path,\"r\") as f:\n",
    "            data = f.read()\n",
    "            extracted_files += data.replace(zip_dir+\"/\",\"\").split(\"\\n\")\n",
    "            \n",
    "\n",
    "    return list(filter(None,extracted_files))\n",
    "\n",
    "def get_geoid(zip_filename):\n",
    "    return zip_filename.split(\".\")[0]\n",
    "\n",
    "def is_zip_dir(filename):\n",
    "    if filename:\n",
    "        return (filename[-1] == \"/\")\n",
    "    return False\n",
    "\n",
    "def get_unprocessed_files():\n",
    "    all_zips = get_all_zip_files()\n",
    "    processed_zips = get_processed_zips()\n",
    "    return [x for x in all_zips if x not in processed_zips]\n",
    "\n",
    "def to_gb(size_in_bytes):\n",
    "    return size_in_bytes / 1073741824\n",
    "\n",
    "def print_mb_as_gbs(size_in_mbytes):\n",
    "    return f'{size_in_mbytes/1024:.0f} GB'\n",
    "\n",
    "def get_extension(filename):\n",
    "    if len(filename.split(\".\")) > 1:\n",
    "        return filename.split(\".\")[-1]\n",
    "    return None\n",
    "\n",
    "def is_pdf(filename):\n",
    "    return (get_extension(filename) == \"pdf\")\n",
    "\n",
    "def is_txt(filename):\n",
    "    return (get_extension(filename) == \"txt\")\n",
    "\n",
    "def is_rtf(filename):\n",
    "    return (get_extension(filename) == \"rtf\")\n",
    "\n",
    "def is_wp(filename):\n",
    "    return (get_extension(filename) == \"wp\")\n",
    "\n",
    "def is_htm(filename):\n",
    "    return ((get_extension(filename) == \"htm\") or (get_extension(filename) == \"html\"))\n",
    "\n",
    "def does_has_of_pdf(filename):\n",
    "    filename = filename.lower()\n",
    "    if (is_pdf(filename)) and (filename.startswith(\"of_\")):\n",
    "        filename_no_ext = (filename.split(\".\")[0])\n",
    "        if (len(filename_no_ext.split(\"_\"))==2) and(filename_no_ext.split(\"_\")[1].isnumeric()):\n",
    "            # mean the format is of_<number>.pdf which would be the report\n",
    "             return True\n",
    "    return False\n",
    "\n",
    "def get_stats(extracted_dir_name,msg=\"PDFs\"):\n",
    "    nb_zips_with_files_extracted = 0\n",
    "    nb_empty_zips = 0\n",
    "    with open(join(extracted_dir,extracted_dir_name,\"extracted.txt\"),\"r+\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            file_and_path = line.strip().split(\":\")\n",
    "            if line[1] == '':\n",
    "                nb_empty_zips +=1\n",
    "            else:\n",
    "                nb_zips_with_files_extracted +=1\n",
    "            \n",
    "    print(f'Number of zips respecting selection criteria and having {msg}:{nb_zips_with_files_extracted}')\n",
    "    print(f'Number of zips respecting selection criteria and not having {msg}:{nb_empty_zips}')\n",
    "\n",
    "class ZipProcessor:\n",
    "    PROCESSED_FILENAME = \"processed.txt\"\n",
    "    IGNORED_FILENAME = \"ignored.txt\"\n",
    "    EXTRACTED_FILENAME = \"extracted.txt\"\n",
    "    \n",
    "    def __init__(self,extraction_dir,zip_file_path):\n",
    "        self.extraction_dir = extraction_dir\n",
    "        self.zip_file_path = zip_file_path\n",
    "        self.extracted_files = []\n",
    "        self.ignored_files = []\n",
    "        # We assume our files are in format <geoscanid>.zip\n",
    "        self.geoscanid = basename(zip_file_path).split(\".\")[0]\n",
    "    \n",
    "    def extract_file(self,filename):\n",
    "        with ZipFile(self.zip_file_path, 'r') as zip_file:\n",
    "            zip_file.extract(filename,self.extraction_dir)\n",
    "            if len(fileparts := filename.split(\"/\")) > 1:\n",
    "                move(join(self.extraction_dir,filename),join(self.extraction_dir,f'{self.geoscanid}_{fileparts[-1]}'))\n",
    "                rmtree(join(self.extraction_dir,fileparts[0]))\n",
    "            else:\n",
    "                rename(join(self.extraction_dir,filename),join(self.extraction_dir,f'{self.geoscanid}_{filename}'))\n",
    "            self.extracted_files.append(filename)\n",
    "    \n",
    "    def ignore_file(self,filename):\n",
    "        self.ignored_files.append(filename)\n",
    "\n",
    "    def finish_processing(self):\n",
    "        with open(join(self.extraction_dir,self.PROCESSED_FILENAME),\"a\") as f:\n",
    "            f.write(f'{self.zip_file_path}\\n')\n",
    "\n",
    "        with open(join(self.extraction_dir,self.EXTRACTED_FILENAME),\"a\") as f:\n",
    "            f.write(f'{self.zip_file_path}:{\",\".join(self.extracted_files)}\\n')\n",
    "\n",
    "        with open(join(self.extraction_dir,self.IGNORED_FILENAME),\"a\") as f:\n",
    "            f.write(f'{self.zip_file_path}:{\",\".join(self.ignored_files)}\\n')\n",
    "    \n",
    "    def has_extracted(self):\n",
    "        if self.extracted_files:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction rules\n",
    "All extracted files will be prefixed geoid_in_zip_file_name. All extracted files could be found in **extracted.txt** file, all ignored files in **ignored.txt** and all processed zips in **processed.txt**\n",
    "\n",
    "Here is the extraction chain. Every files is extracted only once for a given rule,starting with the first one.\n",
    "French files are filtered by removing any files that contain one of the following strings: **\"\\_fr.\",\"\\_fr\\_\",\"-fr\\_\",\"\\_fr-\",\"-fr-\",\"french\"**\n",
    "\n",
    "### 1. Extract **of_number.pdf** files from zips\n",
    "Extract **of_number.pdf** files from zips (if they contain them). Ignore the other files. Put the files in of_pdf directory.\n",
    "\n",
    "### 2. Files containing PDF directory\n",
    "The files are put in has_pdf_dir directory.For files containing PDF directory, extract the pdfs in PDF directory and ignore the rest. The following pdfs are ignored given their content is badly adapted for text search (read tables) or doesnt contain useful text (read maps). If a file contains one of the following words, it will not be extracted. Excluded words: **\"front\",\"statistics\",\"index\",\"bibliography\",\"table_of_contents\",\"author\",\"contents\",\"cover\",\"foreword\",\"plate\",\"preface\",\"table\",\"figure\",\"fig\",\"graph\",\"map\",\"line\",\"appendix\",\"links\",\"locations\",\"count\",\"data\",\"legend\",\"homepage\",\"_tab\",\"_f0\",\"_as_\",\"location\",\"articles\",\"title\"**\n",
    "\n",
    "There is also custom files we decided to ignore for specific geoids (Theses files contain maps, but not text records). These files  geoid are:\n",
    "**213391,224262,211485\"**\n",
    "\n",
    "The following file geoids had their main file extracted manually: **221215,223383,223386,224581,222149,222774,248223,247843,220364,134069,205729,215375,216684,215739,215877,216570,224263,224797,224807,226367,247526**\n",
    "\n",
    "### 3. Other files containing at least one PDF\n",
    "The files are put in generic_pdfs directory.Given the difference of structure of files, more complex rules were needed in order to extract useful files. If a file contains one of the following words, it will not be extracted: **\"front\",\"statistics\",\"index\",\"bibliography\",\"table_of_contents\",\"author\",\"contents\",\"cover\",\"foreword\",\"plate\",\"preface\",\"table\",\"figure\",\"fig\",\"graph\",\"map\",\"line\",\"appendix\",\"links\",\"legend\",\"homepage\",\"sheet\",\"chart\",\"_mn0\",\"_mn1\",\"plan\",\"cross\",\"data\",\"overlay\",\"_nt0\",\"_xs0\",\"_xs1\",\"_xs2\",\"_xs3\",\"_fg0\",\"_fg1\",\"_fg2\",\"_fg3\",\"acrobat\",\"readme\",\"pictou\",\"coulor\",\"reader\",\"licen\",\"start\",\"lisez\",\"carte\",\"disclaimer\",\"_tab_\",\"db_schema\",\"_colour\",\"acknowledgment\",\"trademark\",\"gscmcm_\",\"_mcm\"**. \n",
    "\n",
    "There is also custom files we decided to ignore for specific geoids (Theses files contain maps, but not text records). These files geoid are:\n",
    "**\"100377\",\"109277\",\"119940\",\"123533\",\"127153\",\"127162\",\"127165\",\"127166\",\"127167\",\"127168\", \"127169\",\"127170\",\"127171\",\"127172\",\"127173\",\"127174\",\"127175\",\"127176\",\"127177\",\"127178\",\"127179\",\"127180\",\"127181\",\"127182\",\"127183\",\"127184\",\"127185\",\"127186\",\"127187\",\"127188\",\"127189\",\"127190\",\"127191\",\"127192\",\"127193\",\"127194\",\"127195\",\"127196\",\"127197\",\"127198\",\"127199\",\"127200\",\"127201\",\"127202\",\"127203\",\"127204\",\"127205\",\"127206\",\"127207\",\"127208\",\"129093\",\"129094\",\"129099\",\"129142\",\"129143\",\"129148\",\"129151\",\"129175\",\"129183\",\"129210\",\"129211\",\"129212\",\"129213\",\"129232\",\"129250\",\"129273\",\"129347\",\"129447\",\"129463\",\"129471\",\"129686\",\"129733\",\"130006\",\"130030\",\"130437\",\"130570\",\"130912\",\"132668\",\"183851\",\"208238\",\"208241\",\"209370\",\"210616\",\"210617\",\"210627\",\"210637\",\"211515\",\"212607\",\"214638\",\"215455\",\"222822\",\"224834\",\"247421\",\"247421\",\"247424\",\"247425\",\"247678\",\"285489\",\"285569\",\"286078\",\"286185\",\"286262\",\"287133\",\"287847\",\"290255\",\"8315\"**\n",
    "\n",
    "The folowing files were extracted manually (since there were maps which were harder to remove with generic rules):\n",
    "**\"100357_of_129_AccountLakeSed.pdf\",\"100358_of_0133_Tome1_texte.pdf\",\"100379_of_0471_part_1.pdf\",\"100379_of_0471_part_2.pdf\",\"100500_m_26.pdf\",\"100506_me_32.pdf\",\"100518_me_296.pdf\",\"100547_me_320.pdf\",\"100795_m_385.pdf\",\"100797_me_165.pdf\",\"100794_me_163.pdf\",\"100808_me_176.pdf\",\"100849_me_147.pdf\",\"101153_pa_38-21.pdf\",\"101157_pa_38-16.pdf\",\"101560_me_68.pdf\",\"101569_m_77.pdf\",\"101637_m_211.pdf\",\"101683_m_121.pdf\",\"101793_wp_322.pdf\",\"102157_bu_306.pdf\",\"102307_of_0040_Report.pdf\",\"102433_pa_71-19.pdf\",\"102592_Paper_75-27.pdf\",\"102612_pa_75_41.pdf\",\"102624_pa_76-17.pdf\",\"102634_pa_76-29.pdf\",\"103299_m_372.pdf\",\"104332_bu_276.pdf\",\"108390_pa_51_11.pdf\",\"108440_pa_50_8.pdf\",\"119605_of_1081_Volume1.pdf\",\"119605_of_1081_Volume2.pdf\",\"119605_of_1081_Volume3.pdf\",\"119739_pa_83-31.pdf\",\"119943_me_77_f.pdf\",\"119943_me_77_f.pdf\",\"120589_pa_84-11.pdf\",\"120602_pa_85-16.pdf\",\"123565_rop_1863_Atlas_eng.pdf\",\"123575_rop_1866-69_french_mono.pdf\",\"123889_rop_1866-69_french_part i.pdf\",\"123890_rop_1866-69_french_part ii.pdf\",\"128139_of_2026.pdf\",\"129132_of_0094Report.pdf\",\"129178_of_0116_Report.pdf\",\"129287_of_0487_part_1.pdf\",\"129287_of_0487_part_2.pdf\",\"129333_of_0222_vol1.pdf\",\"129333_of_0222_vol2.pdf\",\"129333_of_0222_vol3.pdf\",\"129408_of_0504_1975_subsea_cable_route_studies.pdf\",\"129408_of_0504_report_on_a_brief_search_for_data.pdf\",\"129470_OF0381BOOK.pdf\",\"129471_of_0382_part2_magnetic_tape_users_manual.pdf\",\"129477_of_0389-ps110.pdf\",\"129477_of_0389-ps111.pdf\",\"129477_of_0389-ps112.pdf\",\"129477_of_0389-ps113.pdf\",\"129477_of_0389-ps114.pdf\",\"129477_of_0389-ps115.pdf\",\"129477_of_0389-ps116.pdf\",\"129477_of_0389-ps201.pdf\",\"129477_of_0389-ps202.pdf\",\"129477_of_0389-ps203.pdf\",\"129477_of_0389-ps204.pdf\",\"129477_of_0389-ps205.pdf\",\"129477_of_0389-ps206.pdf\",\"129477_of_0389-ps207.pdf\",\"129506_of_0605_Part1.pdf\",\"129506_of_0605_Part2.pdf\",\"129511_of_0522a.pdf\",\"129512_of_0522b.pdf\",\"129859_of_0978_vol1.pdf\",\"129859_of_0978_vol2.pdf\",\"129897_of_1116_report.pdf\",\"130263_of_1358.pdf\",\"130281_of_1360.pdf\",\"130282_of_1361.pdf\",\"130283_of_1362.pdf\",\"130284_of_1363.pdf\",\"130285_of_1364.pdf\",\"130761_of_1888_report.pdf\",\"130761_of_1888_report_seismic.pdf\",\"130761_of_1888_report_technical.pdf\",\"130798_of_2110_v2.pdf\",\"130451_of_1921_76E-11.pdf\",\"130451_of_1921_76E-12.pdf\",\"130451_of_1921_76E-13.pdf\",\"130451_of_1921_76E-14.pdf\",\"130483_Of_1638_(21G & 21H).pdf\",\"130484_of_1641.pdf\",\"130485_Of_1642_(74C & 74F).pdf\",\"130592_OF1992BOOK.pdf\",\"130773_OF 2125 vol 1.pdf\",\"193364_OF2439BOOK.pdf\",\"193494_OF2731BOOK.pdf\",\"209907_PART1.PDF\",\"209907_PART2.PDF\",\"209907_PART3.PDF\",\"209907_PART4.PDF\",\"209907_PART5.PDF\",\"209907_PART6.PDF\",\"209907_PART7.PDF\",\"209907_PART8.PDF\",\"209907_PART9.PDF\",\"209907_PART10.PDF\",\"209974_PAPER.PDF\",\"210074_bu_504.pdf\",\"211376_Text.pdf\",\"211434_bu_539.pdf\",\"211641_bu_554.pdf\",\"211793_Report.pdf\",\"211804_of_3954-r.pdf\",\"211874_bu_559.pdf\",\"212098_OF3755_report.pdf\",\"212711_Open File D2952.pdf\",\"212842_OF4115.pdf\",\"213037_saskatchewan.PDF\",\"213996_Title_Page.pdf\",\"210350_bu_498_gsc.pdf\",\"214294_CPT_TEXT.PDF\",\"214294_EM_TEXT.PDF\",\"214294_GPR_TEXT.PDF\",\"214294_INTRO_1.PDF\",\"214294_INTRO_2.PDF\",\"214294_INTRO_3.PDF\",\"214294_PAPERS.PDF\",\"214294_MODELS.PDF\",\"214294_SEISMIC.PDF\",\"214294_SFU_TEXT.PDF\",\"214399_arcexplorer.pdf\",\"214994_OF1670-s.pdf\",\"215634_arcexplorer.pdf\",\"215634_arcexplorer.pdf\",\"221206_mr90_e.pdf\",\"221526_INTRODUCTION.pdf\",\"222773_of5327.pdf\",\"222878_rop_1866-69_mono.pdf\",\"224031_of5350.pdf\",\"224968_Report 90-310.pdf\",\"224968_of_2685.pdf\",\"224968_of_2745.pdf\",\"224968_of_2750.pdf\",\"224968_of_2875.pdf\",\"247630_ar_011_s.pdf\",\"248232_SRreport.pdf\",\"261330_OF5989_CCGS_Hudson_2008-029_cruise_report.pdf\",\"263412_of5611.pdf\",\"291751_Summary.pdf\",\"291931_of_5487_15_App1.pdf\",\"291931_of_5487_15_App2.pdf\",\"291931_of_5487_15_App3.pdf\",\"291931_of_5487_15_App4.pdf\",\"292017_OF7106.pdf\",\"292662_OpenFile7421.pdf\",\"292800_OF7364.pdf\",\"292870_of_7412_report.pdf\",\"293760_Sum_Rep_1924_B.pdf\",\"293877_bu_606_gsc.pdf\",\"295079_bu_604_gsc.pdf\",\"296502_bu_604_gsc.pdf\",\"298718_PAPER.PDF\",\"305397_of_0116Suppl_ReleaseNotice.pdf\",\"307813_cmb_632.pdf\",\"313749_of_0045_gc.pdf\",\"8331_of_78_01.pdf\",\"8747_do_gms_012_015.pdf\",\"8748_do_gms_016_020.pdf\"**\n",
    "\n",
    "### 4. Zip dirs containing txt but no pdf files \n",
    "The files often reference CD media in another format which contain data and observations. We did not attempt to extract the data. \n",
    "\n",
    "### 5. WP and RTFs files\n",
    "These files dont contain PDF or TXT files, but instead contain WP and RTFs files.\n",
    "\n",
    "### 5. Unprocessed files (files which dont contain txt or pdf)\n",
    "**'109528.zip','119487.zip','129399.zip','130457.zip','130911.zip','131318.zip','131699.zip','133405.zip','183968.zip','184082.zip','184150.zip','184214.zip','192437.zip','192442.zip','194063.zip','194079.zip','194080.zip','203270.zip','208314.zip','209916.zip','210093.zip','210113.zip','210377.zip','210902.zip','211290.zip','211693.zip','212642.zip','214521.zip','226533.zip','248120.zip','263390.zip','263391.zip','287420.zip','291819.zip','293108.zip','293154.zip','293658.zip','295695.zip','296405.zip','296406.zip','297628.zip','299666.zip','299667.zip','299668.zip','299728.zip','302765.zip','305337.zip','305363.zip','305827.zip','305828.zip'**\n",
    "\n",
    "### ZIP dirs from which we failed to unzip PDFs:\n",
    "**129399.zip,226672.zip 291819.zip **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4873"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_all_zip_files())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract **of_number.pdf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract file: of_7229.pdf for zip: 291819.zip\n"
     ]
    }
   ],
   "source": [
    "zips_to_process = get_unprocessed_files()\n",
    "for zip_filename in zips_to_process:\n",
    "    try:\n",
    "        zip_processor = ZipProcessor(join(extracted_dir,\"of_pdf\"),join(zip_dir,zip_filename))\n",
    "        with ZipFile(join(zip_dir,zip_filename), 'r') as zip_file:\n",
    "            for filename in zip_file.namelist():\n",
    "                if does_has_of_pdf(filename):\n",
    "                    zip_processor.extract_file(filename)\n",
    "                else:\n",
    "                    zip_processor.ignore_file(filename)\n",
    "        if zip_processor.has_extracted():\n",
    "            zip_processor.finish_processing()\n",
    "    except Exception as err:\n",
    "        print(f'Failed to extract file: {filename} for zip: {zip_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zips respecting selection criteria and having PDFs:1159\n",
      "Number of zips respecting selection criteria and not having PDFs:0\n"
     ]
    }
   ],
   "source": [
    "get_stats(\"of_pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For files containing PDF directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pdfdir_ignore(geoid,filename):\n",
    "    \"\"\"\n",
    "    This function is used to ignore maps, tables and samples for specific GEO Ids\n",
    "    \"\"\"\n",
    "    \n",
    "    if geoid in [\"213391\",\"224262\",\"211485\"]:\n",
    "        return True\n",
    "    \n",
    "    # samples\n",
    "    if geoid == \"221215\" and (not \"Intro4GSCShells.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"223383\" and (not \"ofcat.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"223386\" and (not \"of5442.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"224581\" and (not \"of5660.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"222149\" and (not \"of5088.pdf\" in filename):\n",
    "        return True\n",
    "\n",
    "    if geoid == \"222774\" and (not \"of5343.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"248223\" and (not \"of6274.pdf\" in filename):\n",
    "        return True\n",
    "\n",
    "    if geoid == \"247843\" and (not \"of5574.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"220364\" and (not \"of4887.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    # Extra \n",
    "    if geoid == \"134069\" and (\"_errata\" in filename):\n",
    "        return True\n",
    "\n",
    "    if geoid == \"205729\" and (not \"bu_484.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if (geoid in [\"215375\",\"216684\"]) and (len(basename(filename)) > 8 ):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"215739\" and (not \"GSC_B575.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"215877\" and (not \"GSC_B577.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"216570\" and (not \"GSC_B582.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"224263\" and (not \"of5538.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"224797\" and (not \"B590.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"224807\" and (not \"b_533.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"226367\" and (not \"bu_595.pdf\" in filename):\n",
    "        return True\n",
    "    \n",
    "    if (geoid == \"247526\") and ((len(basename(filename)) > 10 ) and filename != \"592_summary.pdf\"):\n",
    "        return True\n",
    "    \n",
    "    if geoid == \"220345\" and (not \"GSC_B560.pdf\" in filename):\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter_keywords = [\"front\",\"statistics\",\"index\",\"bibliography\",\"table_of_contents\",\"author\",\"contents\",\n",
    "                   \"cover\",\"foreword\",\"plate\",\"preface\",\"table\",\"figure\",\"fig\",\"graph\",\"map\",\"line\",\"appendix\",\n",
    "                   \"links\",\"locations\",\"count\",\"data\",\"legend\",\"homepage\",\"_tab\",\"_f0\",\"as_\",\"location\",\n",
    "                   \"articles\",\"title\"]\n",
    "french_keywords = [\"_fr.\",\"_fr_\",\"-fr_\",\"_fr-\",\"-fr-\",\"french\"]\n",
    "filter_keywords += french_keywords\n",
    "\n",
    "zips_to_process = get_unprocessed_files()\n",
    "for zip_filename in zips_to_process:\n",
    "    try:\n",
    "        zip_processor = ZipProcessor(join(extracted_dir,\"has_pdf_dir\"),join(zip_dir,zip_filename))\n",
    "        with ZipFile(join(zip_dir,zip_filename), 'r') as zip_file:\n",
    "            # check first if it is a PDF DIR\n",
    "            has_pdf_dir = False\n",
    "            for filename in zip_file.namelist():\n",
    "                if len(split_dir := filename.split(\"/\")) > 1 and (split_dir[0].lower() == \"pdf\"):\n",
    "                    # we have at lease one PDF dir so we can extract the data:\n",
    "                    has_pdf_dir = True\n",
    "                    break\n",
    "\n",
    "            if has_pdf_dir:\n",
    "                for filename in zip_file.namelist():\n",
    "                    if is_zip_dir(filename) \\\n",
    "                        or (len(filename) < 4) \\\n",
    "                        or (not filename.lower().startswith(\"pdf\")) \\\n",
    "                        or (not is_pdf(filename.lower())) \\\n",
    "                        or bool([ele for ele in filter_keywords if (ele in filename.lower())]) \\\n",
    "                        or custom_pdfdir_ignore(get_geoid(zip_filename),filename):\n",
    "                        zip_processor.ignore_file(filename)\n",
    "                    else:\n",
    "                        zip_processor.extract_file(filename)\n",
    "                zip_processor.finish_processing()\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f'Failed to extract file: {filename} for zip: {zip_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zips respecting selection criteria and having PDFs:136\n",
      "Number of zips respecting selection criteria and not having PDFs:0\n"
     ]
    }
   ],
   "source": [
    "get_stats(\"has_pdf_dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Other files containing at least one PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_file_by_geoid = [\"100357_of_129_AccountLakeSed.pdf\",\n",
    "                      \"100358_of_0133_Tome1_texte.pdf\",\n",
    "                      \"100379_of_0471_part_1.pdf\",\n",
    "                      \"100379_of_0471_part_2.pdf\",\n",
    "                      \"100500_m_26.pdf\",\n",
    "                      \"100506_me_32.pdf\",\n",
    "                      \"100518_me_296.pdf\",\n",
    "                      \"100547_me_320.pdf\",\n",
    "                      \"100795_m_385.pdf\",\n",
    "                        \"100797_me_165.pdf\",\n",
    "                        \"100794_me_163.pdf\",\n",
    "                        \"100808_me_176.pdf\",\n",
    "                        \"100849_me_147.pdf\",\n",
    "                        \"101153_pa_38-21.pdf\",\n",
    "                        \"101157_pa_38-16.pdf\",\n",
    "                        \"101560_me_68.pdf\",\n",
    "                        \"101569_m_77.pdf\",\n",
    "                        \"101637_m_211.pdf\",\n",
    "                        \"101683_m_121.pdf\",\n",
    "                        \"101793_wp_322.pdf\",\n",
    "                        \"102157_bu_306.pdf\",\n",
    "                        \"102307_of_0040_Report.pdf\",\n",
    "                        \"102433_pa_71-19.pdf\",\n",
    "                        \"102592_Paper_75-27.pdf\",\n",
    "                        \"102612_pa_75_41.pdf\",\n",
    "                        \"102624_pa_76-17.pdf\",\n",
    "                        \"102634_pa_76-29.pdf\",\n",
    "                        \"103299_m_372.pdf\",\n",
    "                        \"104332_bu_276.pdf\",\n",
    "                        \"108390_pa_51_11.pdf\",\n",
    "                        \"108440_pa_50_8.pdf\",\n",
    "                        \"119605_of_1081_Volume1.pdf\",\n",
    "                        \"119605_of_1081_Volume2.pdf\",\n",
    "                        \"119605_of_1081_Volume3.pdf\",\n",
    "                        \"119739_pa_83-31.pdf\",\n",
    "                        \"119943_me_77_f.pdf\",\n",
    "                        \"119943_me_77_f.pdf\",\n",
    "                        \"120589_pa_84-11.pdf\",\n",
    "                        \"120602_pa_85-16.pdf\",\n",
    "                        \"123565_rop_1863_Atlas_eng.pdf\",\n",
    "                        \"123575_rop_1866-69_french_mono.pdf\",\n",
    "                        \"123889_rop_1866-69_french_part i.pdf\",\n",
    "                        \"123890_rop_1866-69_french_part ii.pdf\",\n",
    "                        \"128139_of_2026.pdf\",\n",
    "                        \"129132_of_0094Report.pdf\",\n",
    "                        \"129178_of_0116_Report.pdf\",\n",
    "                        \"129287_of_0487_part_1.pdf\",\n",
    "                        \"129287_of_0487_part_2.pdf\",\n",
    "                        \"129333_of_0222_vol1.pdf\",\n",
    "                        \"129333_of_0222_vol2.pdf\",\n",
    "                        \"129333_of_0222_vol3.pdf\",\n",
    "                        \"129408_of_0504_1975_subsea_cable_route_studies.pdf\",\n",
    "                        \"129408_of_0504_report_on_a_brief_search_for_data.pdf\",\n",
    "                        \"129470_OF0381BOOK.pdf\",\n",
    "                        \"129471_of_0382_part2_magnetic_tape_users_manual.pdf\",\n",
    "                        \"129477_of_0389-ps110.pdf\",\n",
    "                        \"129477_of_0389-ps111.pdf\",\n",
    "                        \"129477_of_0389-ps112.pdf\",\n",
    "                        \"129477_of_0389-ps113.pdf\",\n",
    "                        \"129477_of_0389-ps114.pdf\",\n",
    "                        \"129477_of_0389-ps115.pdf\",\n",
    "                        \"129477_of_0389-ps116.pdf\",\n",
    "                        \"129477_of_0389-ps201.pdf\",\n",
    "                        \"129477_of_0389-ps202.pdf\",\n",
    "                        \"129477_of_0389-ps203.pdf\",\n",
    "                        \"129477_of_0389-ps204.pdf\",\n",
    "                        \"129477_of_0389-ps205.pdf\",\n",
    "                        \"129477_of_0389-ps206.pdf\",\n",
    "                        \"129477_of_0389-ps207.pdf\",\n",
    "                        \"129506_of_0605_Part1.pdf\",\n",
    "                        \"129506_of_0605_Part2.pdf\",\n",
    "                        \"129511_of_0522a.pdf\",\n",
    "                        \"129512_of_0522b.pdf\",\n",
    "                        \"129859_of_0978_vol1.pdf\",\n",
    "                        \"129859_of_0978_vol2.pdf\",\n",
    "                        \"129897_of_1116_report.pdf\",\n",
    "                        \"130263_of_1358.pdf\",\n",
    "                        \"130281_of_1360.pdf\",\n",
    "                        \"130282_of_1361.pdf\",\n",
    "                        \"130283_of_1362.pdf\",\n",
    "                        \"130284_of_1363.pdf\",\n",
    "                        \"130285_of_1364.pdf\",\n",
    "                        \"130761_of_1888_report.pdf\",\n",
    "                        \"130761_of_1888_report_seismic.pdf\",\n",
    "                        \"130761_of_1888_report_technical.pdf\",\n",
    "                        \"130798_of_2110_v2.pdf\",\n",
    "                        \"130451_of_1921_76E-11.pdf\",\n",
    "                        \"130451_of_1921_76E-12.pdf\",\n",
    "                        \"130451_of_1921_76E-13.pdf\",\n",
    "                        \"130451_of_1921_76E-14.pdf\",\n",
    "                        \"130483_Of_1638_(21G & 21H).pdf\",\n",
    "                        \"130484_of_1641.pdf\",\n",
    "                        \"130485_Of_1642_(74C & 74F).pdf\",\n",
    "                        \"130592_OF1992BOOK.pdf\",\n",
    "                        \"130773_OF 2125 vol 1.pdf\",\n",
    "                        \"193364_OF2439BOOK.pdf\",\n",
    "                        \"193494_OF2731BOOK.pdf\",\n",
    "                        \"209907_PART1.PDF\",\n",
    "                        \"209907_PART2.PDF\",\n",
    "                        \"209907_PART3.PDF\",\n",
    "                        \"209907_PART4.PDF\",\n",
    "                        \"209907_PART5.PDF\",\n",
    "                        \"209907_PART6.PDF\",\n",
    "                        \"209907_PART7.PDF\",\n",
    "                        \"209907_PART8.PDF\",\n",
    "                        \"209907_PART9.PDF\",\n",
    "                        \"209907_PART10.PDF\",\n",
    "                        \"209974_PAPER.PDF\",\n",
    "                        \"210074_bu_504.pdf\",\n",
    "                        \"211376_Text.pdf\",\n",
    "                        \"211434_bu_539.pdf\",\n",
    "                        \"211641_bu_554.pdf\",\n",
    "                        \"211793_Report.pdf\",\n",
    "                        \"211804_of_3954-r.pdf\",\n",
    "                        \"211874_bu_559.pdf\",\n",
    "                        \"212098_OF3755_report.pdf\",\n",
    "                        \"212711_Open File D2952.pdf\",\n",
    "                        \"212842_OF4115.pdf\",\n",
    "                        \"213037_saskatchewan.PDF\",\n",
    "                        \"213996_Title_Page.pdf\",\n",
    "                        \"210350_bu_498_gsc.pdf\",\n",
    "                        \"214294_CPT_TEXT.PDF\",\n",
    "                        \"214294_EM_TEXT.PDF\",\n",
    "                        \"214294_GPR_TEXT.PDF\",\n",
    "                        \"214294_INTRO_1.PDF\",\n",
    "                        \"214294_INTRO_2.PDF\",\n",
    "                        \"214294_INTRO_3.PDF\",\n",
    "                        \"214294_PAPERS.PDF\",\n",
    "                        \"214294_MODELS.PDF\",\n",
    "                        \"214294_SEISMIC.PDF\",\n",
    "                        \"214294_SFU_TEXT.PDF\",\n",
    "                        \"214399_arcexplorer.pdf\",\n",
    "                        \"214994_OF1670-s.pdf\",\n",
    "                        \"215634_arcexplorer.pdf\",\n",
    "                        \"215634_arcexplorer.pdf\",\n",
    "                        \"221206_mr90_e.pdf\",\n",
    "                        \"221526_INTRODUCTION.pdf\",\n",
    "                        \"222773_of5327.pdf\",\n",
    "                        \"222878_rop_1866-69_mono.pdf\",\n",
    "                        \"224031_of5350.pdf\",\n",
    "                        \"224968_Report 90-310.pdf\",\n",
    "                        \"224968_of_2685.pdf\",\n",
    "                        \"224968_of_2745.pdf\",\n",
    "                        \"224968_of_2750.pdf\",\n",
    "                        \"224968_of_2875.pdf\",\n",
    "                        \"247630_ar_011_s.pdf\",\n",
    "                        \"248232_SRreport.pdf\",\n",
    "                        \"261330_OF5989_CCGS_Hudson_2008-029_cruise_report.pdf\",\n",
    "                        \"263412_of5611.pdf\",\n",
    "                        \"291751_Summary.pdf\",\n",
    "                        \"291931_of_5487_15_App1.pdf\",\n",
    "                        \"291931_of_5487_15_App2.pdf\",\n",
    "                        \"291931_of_5487_15_App3.pdf\",\n",
    "                        \"291931_of_5487_15_App4.pdf\",\n",
    "                        \"292017_OF7106.pdf\",\n",
    "                        \"292662_OpenFile7421.pdf\",\n",
    "                        \"292800_OF7364.pdf\",\n",
    "                        \"292870_of_7412_report.pdf\",\n",
    "                        \"293760_Sum_Rep_1924_B.pdf\",\n",
    "                        \"293877_bu_606_gsc.pdf\",\n",
    "                        \"295079_bu_604_gsc.pdf\",\n",
    "                        \"296502_bu_604_gsc.pdf\",\n",
    "                        \"298718_PAPER.PDF\",\n",
    "                        \"305397_of_0116Suppl_ReleaseNotice.pdf\",\n",
    "                        \"307813_cmb_632.pdf\",\n",
    "                        \"313749_of_0045_gc.pdf\",\n",
    "                        \"8331_of_78_01.pdf\",\n",
    "                        \"8747_do_gms_012_015.pdf\",\n",
    "                        \"8748_do_gms_016_020.pdf\",\n",
    "\n",
    "                     ]\n",
    "\n",
    "files_by_geoid = dict()\n",
    "for file in filter_file_by_geoid:\n",
    "    geoid = file.split(\"_\")[0]\n",
    "    base_file_name = file[len(geoid)+1:]\n",
    "    if not geoid in files_by_geoid:\n",
    "        files_by_geoid[geoid] = []\n",
    "    files_by_geoid[geoid].append(base_file_name)\n",
    "\n",
    "#224834 having french journal articles about earthquakes. Not sure we need that.\n",
    "\n",
    "def custom_pdf_generic_ignore(geoid,filename):\n",
    "    if geoid in [\"100377\",\"109277\",\"119940\",\"123533\",\"127153\",\"127162\",\"127165\",\"127166\",\"127167\",\"127168\", \n",
    "                 \"127169\",\"127170\",\"127171\",\"127172\",\"127173\",\"127174\",\"127175\",\"127176\",\"127177\", \n",
    "                 \"127178\",\"127179\",\"127180\",\"127181\",\"127182\",\"127183\",\"127184\",\"127185\",\"127186\", \n",
    "                 \"127187\",\"127188\",\"127189\",\"127190\",\"127191\",\"127192\",\"127193\",\"127194\",\"127195\", \n",
    "                 \"127196\",\"127197\",\"127198\",\"127199\",\"127200\",\"127201\",\"127202\",\"127203\",\"127204\", \n",
    "                 \"127205\",\"127206\",\"127207\",\"127208\",\"129093\",\"129094\",\"129099\",\"129142\",\"129143\", \n",
    "                 \"129148\",\"129151\",\"129175\",\"129183\",\"129210\",\"129211\",\"129212\",\"129213\",\"129232\",\n",
    "                 \"129250\",\"129273\",\"129347\",\"129447\",\"129463\",\"129471\",\"129686\",\"129733\",\"130006\",\n",
    "                 \"130030\",\"130437\",\"130570\",\"130912\",\"132668\",\"183851\",\"208238\",\"208241\",\"209370\",\n",
    "                 \"210616\",\"210617\",\"210627\",\"210637\",\"211515\",\"212607\",\"214638\",\"215455\",\"222822\",\n",
    "                 \"224834\",\"247421\",\"247421\",\"247424\",\"247425\",\"247678\",\"285489\",\"285569\",\"286078\",\n",
    "                 \"286185\",\"286262\",\"287133\",\"287847\",\"290255\",\"8315\"\n",
    "                ]:\n",
    "        return True\n",
    "    \n",
    "    if geoid in files_by_geoid and not (basename(filename) in files_by_geoid[geoid]):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "rm -rf /nrcan_p2/data/01_raw/20201117/geoscan/raw/extracted/generic_pdfs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract file: OF_283_Halifax_Harbour_Bottom_Survey_1974_Seismic_Reflection_Profiles.pdf for zip: 129399.zip\n",
      "Failed to extract file: Earthquake-catalogue.pdf for zip: 226672.zip\n",
      "Failed to extract file: of_7229.pdf for zip: 291819.zip\n"
     ]
    }
   ],
   "source": [
    "zips_to_process = get_unprocessed_files()\n",
    "filter_keywords = [\"front\",\"statistics\",\"index\",\"bibliography\",\"table_of_contents\",\n",
    "                   \"author\",\"contents\",\"cover\",\"foreword\",\"plate\",\"preface\",\n",
    "                   \"table\",\"figure\",\"fig\",\"graph\",\"map\",\"line\",\"appendix\",\n",
    "                   \"links\",\"legend\",\"homepage\",\"sheet\",\"chart\",\"_mn0\",\"_mn1\",\"plan\",\n",
    "                   \"cross\",\"data\",\"overlay\",\"_nt0\",\"_xs0\",\"_xs1\",\"_xs2\",\"_xs3\",\n",
    "                   \"_fg0\",\"_fg1\",\"_fg2\",\"_fg3\",\"acrobat\",\"readme\",\"pictou\",\"coulor\",\n",
    "                   \"reader\",\"licen\",\"start\",\"lisez\",\"carte\",\"disclaimer\",\"_tab_\",\n",
    "                   \"db_schema\",\"_colour\",\"acknowledgment\",\"trademark\",\"gscmcm_\",\"_mcm\",]\n",
    "\n",
    "french_keywords = [\"_fr.\",\"_fr_\",\"-fr_\",\"_fr-\",\"-fr-\",\"french\"]\n",
    "filter_keywords += french_keywords\n",
    "\n",
    "for zip_filename in zips_to_process:\n",
    "    try:\n",
    "        zip_processor = ZipProcessor(join(extracted_dir,\"generic_pdfs\"),join(zip_dir,zip_filename))\n",
    "        with ZipFile(join(zip_dir,zip_filename), 'r') as zip_file:\n",
    "            # check first if has a pdf\n",
    "            has_pdf = False\n",
    "            for filename in zip_file.namelist():\n",
    "                if get_extension(filename.lower()) == \"pdf\":\n",
    "                    has_pdf = True\n",
    "                    break\n",
    "\n",
    "            if has_pdf:\n",
    "                for filename in zip_file.namelist():\n",
    "                    if is_zip_dir(filename) \\\n",
    "                        or (not is_pdf(filename.lower())) \\\n",
    "                        or bool([ele for ele in filter_keywords if (ele in filename.lower())]) \\\n",
    "                        or custom_pdf_generic_ignore(get_geoid(zip_filename),filename):\n",
    "                        zip_processor.ignore_file(filename)\n",
    "                    else:\n",
    "                        zip_processor.extract_file(filename)\n",
    "                zip_processor.finish_processing()\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f'Failed to extract file: {filename} for zip: {zip_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zips respecting selection criteria and having PDFs:3439\n",
      "Number of zips respecting selection criteria and not having PDFs:0\n"
     ]
    }
   ],
   "source": [
    "get_stats(\"generic_pdfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Zip dirs containing txt but no pdf files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_file_by_geoid = [\"205313_OF2867.TXT\",\n",
    "                        \"205313_OF2868.TXT\",\n",
    "                        \"205313_OF2974.TXT\",\n",
    "                        \"208180_VOL-I.TXT\",\n",
    "                        \"208180_VOL-II.TXT\",\n",
    "                        \n",
    "                       ]\n",
    "\n",
    "files_by_geoid = dict()\n",
    "for file in filter_file_by_geoid:\n",
    "    geoid = file.split(\"_\")[0]\n",
    "    base_file_name = file[len(geoid)+1:]\n",
    "    if not geoid in files_by_geoid:\n",
    "        files_by_geoid[geoid] = []\n",
    "    files_by_geoid[geoid].append(base_file_name)\n",
    "    \n",
    "\n",
    "def custom_txt_generic_ignore(geoid,filename):\n",
    "    if geoid in [\"195142\",\"203760\",\"205765\",\"208515\",\"209895\"]:\n",
    "        return True\n",
    "    \n",
    "    if geoid in files_by_geoid and not (basename(filename) in files_by_geoid[geoid]):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "rm -rf /nrcan_p2/data/01_raw/20201117/geoscan/raw/extracted/txt/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: That compression method is not supported. Failed to extract file: ECW/list.txt for zip: 291819.zip\n"
     ]
    }
   ],
   "source": [
    "zips_to_process = get_unprocessed_files()\n",
    "filter_keywords = [\"front\",\"statistics\",\"index\",\"bibliography\",\"table_of_contents\",\n",
    "                   \"author\",\"contents\",\"cover\",\"foreword\",\"plate\",\"preface\",\n",
    "                   \"table\",\"figure\",\"fig\",\"graph\",\"map\",\"line\",\"appendix\",\n",
    "                   \"links\",\"legend\",\"homepage\",\"sheet\",\"chart\",\"_mn0\",\"_mn1\",\"plan\",\n",
    "                   \"cross\",\"data\",\"overlay\",\"_nt0\",\"_xs0\",\"_xs1\",\"_xs2\",\"_xs3\",\n",
    "                   \"_fg0\",\"_fg1\",\"_fg2\",\"_fg3\",\"acrobat\",\"readme\",\"pictou\",\"coulor\",\n",
    "                   \"reader\",\"licen\",\"start\",\"lisez\",\"carte\",\"disclaimer\",\"_tab_\",\n",
    "                   \"db_schema\",\"_colour\",\"acknowledgment\",\"trademark\",\"gscmcm_\",\"_mcm\",]\n",
    "\n",
    "french_keywords = [\"_fr.\",\"_fr_\",\"-fr_\",\"_fr-\",\"-fr-\",\"french\"]\n",
    "filter_keywords += french_keywords\n",
    "for zip_filename in zips_to_process:\n",
    "    try:\n",
    "        zip_processor = ZipProcessor(join(extracted_dir,\"txt\"),join(zip_dir,zip_filename))\n",
    "        with ZipFile(join(zip_dir,zip_filename), 'r') as zip_file:\n",
    "            # check first if it has a txt\n",
    "            has_txt = False\n",
    "            for filename in zip_file.namelist():\n",
    "                if get_extension(filename.lower()) == \"txt\":\n",
    "                    has_txt = True\n",
    "                    break\n",
    "\n",
    "            if has_txt:\n",
    "                for filename in zip_file.namelist():\n",
    "                    if is_zip_dir(filename) \\\n",
    "                        or (not is_txt(filename.lower())) \\\n",
    "                        or bool([ele for ele in filter_keywords if (ele in filename.lower())]) \\\n",
    "                        or custom_txt_generic_ignore(get_geoid(zip_filename),filename):\n",
    "                        zip_processor.ignore_file(filename)\n",
    "                    else:\n",
    "                        zip_processor.extract_file(filename)\n",
    "                zip_processor.finish_processing()\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f'Error: {err}. Failed to extract file: {filename} for zip: {zip_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zips respecting selection criteria and having txt:79\n",
      "Number of zips respecting selection criteria and not having txt:0\n"
     ]
    }
   ],
   "source": [
    "get_stats(\"txt\",\"txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. WP and RTFs files  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: That compression method is not supported. Failed to extract file: Readme.rtf for zip: 291819.zip\n"
     ]
    }
   ],
   "source": [
    "zips_to_process = get_unprocessed_files()\n",
    "for zip_filename in zips_to_process:\n",
    "    try:\n",
    "        zip_processor = ZipProcessor(join(extracted_dir,\"wp_rtf\"),join(zip_dir,zip_filename))\n",
    "        with ZipFile(join(zip_dir,zip_filename), 'r') as zip_file:\n",
    "            for filename in zip_file.namelist():\n",
    "                if is_zip_dir(filename) or (not (is_wp(filename.lower()) or is_rtf(filename.lower()))):\n",
    "                    zip_processor.ignore_file(filename)\n",
    "                else:\n",
    "                    zip_processor.extract_file(filename)\n",
    "            if zip_processor.has_extracted():\n",
    "                zip_processor.finish_processing()\n",
    "    except Exception as err:\n",
    "        print(f'Error: {err}. Failed to extract file: {filename} for zip: {zip_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zips respecting selection criteria and having WP and RTF files:10\n",
      "Number of zips respecting selection criteria and not having WP and RTF files:0\n"
     ]
    }
   ],
   "source": [
    "get_stats(\"wp_rtf\",\"WP and RTF files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Unprocessed files (files which dont contain txt or pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_unprocessed_files())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['109528.zip',\n",
       " '119487.zip',\n",
       " '129399.zip',\n",
       " '130457.zip',\n",
       " '130911.zip',\n",
       " '131318.zip',\n",
       " '131699.zip',\n",
       " '133405.zip',\n",
       " '183968.zip',\n",
       " '184082.zip',\n",
       " '184150.zip',\n",
       " '184214.zip',\n",
       " '192437.zip',\n",
       " '192442.zip',\n",
       " '194063.zip',\n",
       " '194079.zip',\n",
       " '194080.zip',\n",
       " '203270.zip',\n",
       " '208314.zip',\n",
       " '209916.zip',\n",
       " '210093.zip',\n",
       " '210113.zip',\n",
       " '210377.zip',\n",
       " '210902.zip',\n",
       " '211290.zip',\n",
       " '211693.zip',\n",
       " '212642.zip',\n",
       " '214521.zip',\n",
       " '226533.zip',\n",
       " '248120.zip',\n",
       " '263390.zip',\n",
       " '263391.zip',\n",
       " '287420.zip',\n",
       " '291819.zip',\n",
       " '293108.zip',\n",
       " '293154.zip',\n",
       " '293658.zip',\n",
       " '295695.zip',\n",
       " '296405.zip',\n",
       " '296406.zip',\n",
       " '297628.zip',\n",
       " '299666.zip',\n",
       " '299667.zip',\n",
       " '299668.zip',\n",
       " '299728.zip',\n",
       " '302765.zip',\n",
       " '305337.zip',\n",
       " '305363.zip',\n",
       " '305827.zip',\n",
       " '305828.zip']"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unprocessed_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Extracting maps, crossections and other combinations of maps and textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract file: OF_283_Bedford_Basin_Lines_305_to_end_of_line.pdf for zip: 129399.zip\n"
     ]
    }
   ],
   "source": [
    "zips_to_process = get_all_zip_files()\n",
    "filters_to_keep = [\"front\",\"plate\",\"figure\",\"fig\",\"graph\",\"map\",\"line\",\"appendix\",\n",
    "                   \"legend\",\"sheet\",\"chart\",\"_mn0\",\"_mn1\",\"plan\",\n",
    "                   \"cross\",\"overlay\",\"_nt0\",\"_xs0\",\"_xs1\",\"_xs2\",\"_xs3\",\n",
    "                   \"_fg0\",\"_fg1\",\"_fg2\",\"_fg3\",\"gscmcm_\",\"_mcm\",]\n",
    "\n",
    "for zip_filename in zips_to_process:\n",
    "    try:\n",
    "        zip_processor = ZipProcessor(join(extracted_dir,\"low_text_pdfs\"),join(zip_dir,zip_filename))\n",
    "        with ZipFile(join(zip_dir,zip_filename), 'r') as zip_file:\n",
    "            for filename in zip_file.namelist():\n",
    "                lfile_name= filename.lower()\n",
    "                has_pdf = False\n",
    "                for filename in zip_file.namelist():\n",
    "                    if get_extension(lfile_name) == \"pdf\":\n",
    "                        has_pdf = True\n",
    "                        break\n",
    "            \n",
    "                if has_pdf:\n",
    "                    for filename in zip_file.namelist():\n",
    "                        if not is_pdf(filename) or \\\n",
    "                            not bool([ele for ele in filters_to_keep if (ele in filename.lower())]):\n",
    "                            zip_processor.ignore_file(filename)\n",
    "                        else:\n",
    "                            zip_processor.extract_file(filename)\n",
    "                    \n",
    "                    if zip_processor.has_extracted():\n",
    "                        zip_processor.finish_processing()\n",
    "                        \n",
    "    except Exception as err:\n",
    "        print(f'Failed to extract file: {filename} for zip: {zip_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zips respecting selection criteria and having Extra pdfs with low text:27321\n",
      "Number of zips respecting selection criteria and not having Extra pdfs with low text:0\n"
     ]
    }
   ],
   "source": [
    "get_stats(\"low_text_pdfs\",\"Extra pdfs with low text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting french files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/tmp\n",
    "rm -rf /nrcan_p2/data/01_raw/20201117/geoscan/raw/tmp/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_raw=\"/nrcan_p2/data/01_raw/20201117/geoscan/raw/tmp\"\n",
    "zips_to_process = get_all_zip_files()\n",
    "count = 0\n",
    "\n",
    "for zip_filename in zips_to_process:\n",
    "    try:\n",
    "        with ZipFile(join(zip_dir,zip_filename), 'r') as zip_file:\n",
    "            # check first if has a pdf\n",
    "            has_pdf = False\n",
    "            for filename in zip_file.namelist():\n",
    "                if get_extension(filename.lower()) == \"pdf\":\n",
    "                    has_pdf = True\n",
    "                    break\n",
    "\n",
    "            if has_pdf:\n",
    "                \n",
    "    except Exception as err:\n",
    "        print(f'Failed to extract file: {filename} for zip: {zip_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing extra files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p /nrcan_p2/data/01_raw/20201117/geoscan/raw/extra_tests\n",
    "rm -rf /nrcan_p2/data/01_raw/20201117/geoscan/raw/extra_tests/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_keywords = [\"front\",\"statistics\",\"index\",\"bibliography\",\"table_of_contents\",\n",
    "                   \"author\",\"contents\",\"cover\",\"foreword\",\"plate\",\"preface\",\n",
    "                   \"table\",\"figure\",\"fig\",\"graph\",\"map\",\"line\",\"appendix\",\n",
    "                   \"links\",\"legend\",\"homepage\",\"sheet\",\"chart\",\"_mn0\",\"_mn1\",\"plan\",\n",
    "                   \"cross\",\"data\",\"overlay\",\"_nt0\",\"_xs0\",\"_xs1\",\"_xs2\",\"_xs3\",\n",
    "                   \"_fg0\",\"_fg1\",\"_fg2\",\"_fg3\",\"acrobat\",\"readme\",\"pictou\",\"coulor\",\n",
    "                   \"reader\",\"licen\",\"start\",\"lisez\",\"carte\",\"disclaimer\",\"_tab_\",\n",
    "                   \"db_schema\",\"_colour\",\"acknowledgment\",\"trademark\",\"gscmcm_\",\"_mcm\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_keyword = dict()\n",
    "for keyword in filter_keywords:\n",
    "    count_by_keyword[keyword] =0\n",
    "    MAX_KEYWORD_COUNT=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tests=\"/nrcan_p2/data/01_raw/20201117/geoscan/raw/extra_tests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract file: OF_283_Bedford_Basin_Lines_328_to_end_of_line_Time_Start_1848_.pdf for zip: 129399.zip\n"
     ]
    }
   ],
   "source": [
    "zips_to_process = get_all_zip_files()\n",
    "for zip_filename in zips_to_process:\n",
    "    try:\n",
    "        with ZipFile(join(zip_dir,zip_filename), 'r') as zip_file:\n",
    "            already_used = False\n",
    "            for filename in zip_file.namelist():\n",
    "                if already_used:\n",
    "                    break\n",
    "                lfile_name= filename.lower()\n",
    "                if is_pdf(lfile_name):\n",
    "                    for keyword in filter_keywords:\n",
    "                        if (keyword in lfile_name) and (count_by_keyword[keyword] < MAX_KEYWORD_COUNT):\n",
    "                            count_by_keyword[keyword] +=1\n",
    "                            zip_file.extract(filename,extra_tests)\n",
    "                            geoscan_id =zip_filename.split(\"_\")[0]\n",
    "                            if len(fileparts := filename.split(\"/\")) > 1:\n",
    "                                move(join(extra_tests,filename),join(extra_tests,f'{keyword}_{geoscan_id}_{fileparts[-1]}'))\n",
    "                                rmtree(join(extra_tests,fileparts[0]))\n",
    "                            else:\n",
    "                                rename(join(extra_tests,filename),join(extra_tests,f'{keyword}_{geoscan_id}_{filename}'))\n",
    "                            \n",
    "                            already_used = True\n",
    "                            break\n",
    "                \n",
    "    except Exception as err:\n",
    "        print(f'Failed to extract file: {filename} for zip: {zip_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
